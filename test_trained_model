import os
import gymnasium as gym
import numpy as np
import random
import json
from stable_baselines3 import SAC
import torch

def test_model_with_render(env, model, n_episodes, max_total_steps=100_000):
    """
    Prueba el modelo entrenado en el entorno con renderizado para visualizar la política.
    """
    total_reward = 0
    total_steps = 0

    for episode in range(n_episodes):
        obs, _ = env.reset()
        done = False
        episode_reward = 0
        episode_steps = 0

        print(f"--- Episode {episode + 1} ---")
        while not done and episode_steps < max_total_steps:
            env.render()  # Renderizar el entorno
            action, _ = model.predict(obs, deterministic=True)  # Política aprendida
            obs, reward, done, truncated, _ = env.step(action)
            episode_reward += reward
            episode_steps += 1

            if done or truncated:
                print(f"Episode {episode + 1} finished with reward: {episode_reward} and steps: {episode_steps}")
                break

        total_reward += episode_reward
        total_steps += episode_steps

    avg_reward = total_reward / n_episodes
    avg_steps = total_steps / n_episodes
    print(f"\nAverage Reward: {avg_reward}")
    print(f"Average Steps: {avg_steps}")

if __name__ == "__main__":
    # Configuración del entorno
    
    
    env_name = "Ant-v5"
    
    env = gym.make('Ant-v5', 
                   xml_file='./mujoco_menagerie/unitree_go1/scene.xml',
                   forward_reward_weight=0,
                   ctrl_cost_weight=0,
                   contact_cost_weight=0,
                   healthy_reward=0,
                   main_body=1,
                   healthy_z_range=(0, np.inf),
                   include_cfrc_ext_in_observation=True,
                   exclude_current_positions_from_observation=False,
                   reset_noise_scale=0,
                   frame_skip=1,
                   max_episode_steps=1_000_000,render_mode = 'human_mode')

    # Ruta del modelo guardado
    model_path = "sac_ant_best_model/sac_ant_model.zip"

    # Comprobar si existe el modelo guardado
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"No trained model found at {model_path}. Train a model first.")

    # Cargar el modelo entrenado
    print(f"Loading the model from {model_path}...")
    model = SAC.load(model_path)

    # Probar el modelo con renderizado
    print("Testing the model with rendering...")
    test_model_with_render(env, model, n_episodes=5)

    # Cerrar el entorno
    env.close()
